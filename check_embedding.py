import os
import numpy as np
import h5py
from datetime import datetime

DB_PATH = "embeddings_db.h5"

def print_separator():
    print("=" * 80)

def print_header(title):
    print_separator()
    print(f" {title.upper()} ".center(80, "="))
    print_separator()

def analyze_embedding_quality(embedding):
    """Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng embedding"""
    try:
        # Chuy·ªÉn ƒë·ªïi sang numpy array v√† ƒë·∫£m b·∫£o ki·ªÉu d·ªØ li·ªáu
        embedding = np.asarray(embedding, dtype=np.float32)
        
        # Ki·ªÉm tra n·∫øu embedding r·ªóng
        if embedding.size == 0:
            return {'quality': 'Empty', 'dims': (0,), 'error': 'Empty embedding'}
        
        # T√≠nh to√°n c√°c th√¥ng s·ªë
        norm = float(np.linalg.norm(embedding))
        mean_val = float(np.mean(embedding))
        std_val = float(np.std(embedding))
        min_val = float(np.min(embedding))
        max_val = float(np.max(embedding))
        
        # ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng
        quality = "Good"
        error_msg = None
        
        # Ki·ªÉm tra NaN v√† inf
        has_nan = np.any(np.isnan(embedding))
        has_inf = np.any(np.isinf(embedding))
        if has_nan or has_inf:
            quality = "Corrupted"
            error_msg = "Contains NaN or Inf"
        elif norm < 0.9 or norm > 1.1:
            quality = "Suspicious"
            error_msg = f"Unusual norm: {norm:.3f}"
        
        result = {
            'dims': embedding.shape,
            'norm': norm,
            'mean': mean_val,
            'std': std_val,
            'range': (min_val, max_val),
            'quality': quality
        }
        
        if error_msg:
            result['error'] = error_msg
            
        return result
        
    except Exception as e:
        return {
            'quality': 'Error',
            'dims': 'Unknown',
            'error': str(e)
        }

def check_h5_database():
    """Ki·ªÉm tra v√† ph√¢n t√≠ch database H5"""
    print_header("HDF5 FACE RECOGNITION DATABASE CHECKER")
    
    if not os.path.exists(DB_PATH):
        print("‚ùå Database kh√¥ng t·ªìn t·∫°i.")
        return
    
    try:
        with h5py.File(DB_PATH, 'r') as f:
            # ƒê·ªçc metadata
            if 'metadata' in f:
                print(f"üìÅ File: {DB_PATH}")
                print(f"üìù Phi√™n b·∫£n: {f['metadata'].attrs.get('version', 'N/A')}")
                print(f"‚è∞ T·∫°o l√∫c: {f['metadata'].attrs.get('created_at', 'N/A')}")
                print(f"‚è∞ C·∫≠p nh·∫≠t l·∫ßn cu·ªëi: {f['metadata'].attrs.get('updated_at', 'N/A')}")
                print(f"üìÑ M√¥ t·∫£: {f['metadata'].attrs.get('description', 'N/A')}")
            else:
                print(f"üìÅ File: {DB_PATH}")
                print("‚ö†Ô∏è Kh√¥ng c√≥ metadata")
            
            # ƒê·ªçc danh s√°ch t√™n
            if 'names' in f:
                raw_names = list(f['names'][()])
                names = []
                for n in raw_names:
                    if isinstance(n, bytes):
                        try:
                            names.append(n.decode('utf-8'))
                        except Exception:
                            names.append(n.decode('latin1', errors='ignore'))
                    else:
                        names.append(str(n))
                print(f"üë• S·ªë ng∆∞·ªùi: {len(names)}")
            else:
                print("‚ùå Kh√¥ng c√≥ danh s√°ch t√™n")
                return
            
            print(f"üíæ K√≠ch th∆∞·ªõc file: {os.path.getsize(DB_PATH) / 1024:.1f} KB")
            
            # Ki·ªÉm tra c·∫•u tr√∫c
            has_embeddings = 'embeddings' in f
            has_avg_embeddings = 'avg_embeddings' in f
            
            if has_embeddings:
                print("‚úÖ C√≥ embeddings")
            else:
                print("‚ùå Kh√¥ng c√≥ embeddings")
                
            if has_avg_embeddings:
                print("‚úÖ C√≥ average embeddings")
            else:
                print("‚ùå Kh√¥ng c√≥ average embeddings")
            
            print("\nüë• CHI TI·∫æT T·ª™NG NG∆Ø·ªúI:")
            print("-" * 80)
            
            total_samples = 0
            
            for i, name in enumerate(names):
                print(f"\nüîπ Ng∆∞·ªùi th·ª© {i+1}: {name}")
                
                # Ki·ªÉm tra embeddings
                emb_path = f"embeddings/{name}"
                if emb_path in f:
                    embeddings = f[emb_path][()]
                    num_samples = embeddings.shape[0] if embeddings.ndim > 1 else 1
                    total_samples += num_samples
                    
                    print(f"   üì∏ S·ªë l∆∞·ª£ng m·∫´u: {num_samples}")
                    
                    if 'updated_at' in f[emb_path].attrs:
                        print(f"   ‚è∞ C·∫≠p nh·∫≠t: {f[emb_path].attrs['updated_at']}")
                    
                    # Ph√¢n t√≠ch m·∫´u
                    if num_samples > 0:
                        sample_count = min(3, num_samples)
                        for j in range(sample_count):
                            if embeddings.ndim > 1:
                                emb = embeddings[j]
                            else:
                                emb = embeddings
                                
                            quality_info = analyze_embedding_quality(emb)
                            error_str = f" | Error: {quality_info['error']}" if 'error' in quality_info else ""
                            print(f"   üî∏ M·∫´u {j+1}: {quality_info['dims']} | Norm: {quality_info['norm']:.3f} | Quality: {quality_info['quality']}{error_str}")
                        
                        if num_samples > 3:
                            print(f"   ... v√† {num_samples-3} m·∫´u kh√°c")
                else:
                    print("   ‚ùå Kh√¥ng c√≥ embeddings")
                
                # Ki·ªÉm tra average embedding
                avg_path = f"avg_embeddings/{name}"
                if avg_path in f:
                    avg_emb = f[avg_path][()]
                    quality_info = analyze_embedding_quality(avg_emb)
                    error_str = f" | Error: {quality_info['error']}" if 'error' in quality_info else ""
                    print(f"   üéØ Average: {quality_info['dims']} | Norm: {quality_info['norm']:.3f} | Quality: {quality_info['quality']}{error_str}")
                    
                    # L·∫•y th√¥ng tin ch·∫•t l∆∞·ª£ng t·ª´ thu·ªôc t√≠nh
                    if 'quality' in f[avg_path].attrs:
                        quality = f[avg_path].attrs['quality']
                        norm = f[avg_path].attrs.get('norm', 0.0)
                        print(f"   ‚ö†Ô∏è  ƒê√°nh gi√°: {quality.upper()} | Norm: {norm:.3f}")
                else:
                    print("   ‚ùå Kh√¥ng c√≥ average embedding")
            
            # T·ªïng k·∫øt
            print("\n" + "=" * 80)
            print(f"üìä T·ªîNG K·∫æT:")
            print(f"   üë• S·ªë ng∆∞·ªùi: {len(names)}")
            print(f"   üî¢ T·ªïng s·ªë m·∫´u: {total_samples}")
            print(f"   üíæ K√≠ch th∆∞·ªõc file: {os.path.getsize(DB_PATH) / 1024:.1f} KB")
            
            # G·ª£i √Ω
            print("\nüí° G·ª¢I √ù:")
            print("  - N·∫øu quality = 'Suspicious', h√£y ghi danh l·∫°i")
            print("  - N·∫øu quality = 'Corrupted', h√£y x√≥a v√† ghi danh l·∫°i")
            print("  - Norm t·ªët n√™n trong kho·∫£ng 0.9 - 1.1")
            print("  - Nhi·ªÅu m·∫´u (>15) s·∫Ω cho ƒë·ªô ch√≠nh x√°c cao h∆°n")
            
    except Exception as e:
        print(f"‚ùå L·ªói khi ƒë·ªçc database: {e}")

if __name__ == "__main__":
    check_h5_database()